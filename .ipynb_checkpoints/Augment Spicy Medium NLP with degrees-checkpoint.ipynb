{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a New Tag for NER\n",
    "\n",
    "Given a dataframe with label name, pattern and pattern id in a given file\n",
    "create a new ruler and add the ruler to the original nlp.\n",
    "File name: Degrees and Acronymns.csv\n",
    "File Columns: \n",
    "   DegreeName (Bachelor, Master, or Doctor)\n",
    "   DegreeAcronym (all the synonyms to a given degree)\n",
    "   Type: in this case is EDU\n",
    "\n",
    "Spicy file used is en_core_web_md which is augmented with Degrees and Acronyms.  The new pipe file is stored in local directory that can be caused using spacy.load\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "from spacy.pipeline import EntityRuler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read file, and load the nlp\n",
    "degrees_df = pd.read_csv(\"../Degrees And Acronyms.csv\") \n",
    "nlp = spacy.load(\"en_core_web_md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the new labeled Entities and their classification to nlp, and save the result in local directory\n",
    "ruler = EntityRuler(nlp)\n",
    "for row in degrees_df.itertuples():\n",
    "        ruler.add_patterns([{\"label\": row.Type, \"pattern\": row.DegreeAcronym,\"id\":row.DegreeName}])\n",
    "nlp.add_pipe(ruler,before =\"ner\") \n",
    "nlp.to_disk(\"./\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If one wants to upload the new nlp, one just need to use spacy.load and provide the path to the file (.json file type)\n",
    "nlp = spacy.load('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('BA', 'EDU', 'Bachelor')]\n",
      "Bachelor\n"
     ]
    }
   ],
   "source": [
    "#Example use\n",
    "def extract_degree_level(s):\n",
    "    doc = nlp(s)\n",
    "    degree = \"\"\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"EDU\":\n",
    "            degree = ent.ent_id_\n",
    "            return(degree)\n",
    "    return degree \n",
    "tp = extract_degree_level(\"BA in Computer Science\")\n",
    "if tp:\n",
    "    print(tp)\n",
    "else:\n",
    "    print(\"not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tagger', <spacy.pipeline.pipes.Tagger object at 0x7f96087f29d0>), ('parser', <spacy.pipeline.pipes.DependencyParser object at 0x7f96087cf670>), ('ner', <spacy.pipeline.pipes.EntityRecognizer object at 0x7f96087cfe50>)]\n"
     ]
    }
   ],
   "source": [
    "#If one get an error when creating a new nlp, just do the following\n",
    "nlp.remove_pipe(\"entity_ruler\")\n",
    "print(nlp.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dalila.benachenhou/Documents/HSS/HSS_Resumes'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE 1999\n",
      "EDU Ph.D.\n",
      "ORG The Pennsylvania State University\n",
      "GPE University Park\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"1999: Ph.D. Mechanical Engineering, The Pennsylvania State University, University Park, PA\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.label_,ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"1999: Ph.D. Mechanical Engineering, The Pennsylvania State University, University Park, PA\"\n",
    "s = s.replace(\"1999\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s.replace(\"The Pennsylvania State University\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "': Ph.D. Mechanical Engineering, , University Park, PA'"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (HSS_Resumes)",
   "language": "python",
   "name": "pycharm-727f0d03"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

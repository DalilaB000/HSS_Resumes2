{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/dalila.benachenhou/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/dalila.benachenhou/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     /Users/dalila.benachenhou/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     /Users/dalila.benachenhou/nltk_data...\n",
      "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/dalila.benachenhou/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/dalila.benachenhou/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import geograpy3\n",
    "import spacy\n",
    "import os\n",
    "import spacy\n",
    "from find_job_titles import FinderAcora\n",
    "import pandas as pd\n",
    "import re\n",
    "from ipykernel import kernelapp as app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from nltk import RegexpParser\\nfrom nltk import Tree\\nfrom nltk.tokenize import sent_tokenize, word_tokenize\\nfrom nltk.corpus import stopwords'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "'''from nltk import RegexpParser\n",
    "from nltk import Tree\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Load en_core_web_md augmented\n",
    "nlp = spacy.load('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Get Dictionary of Experience\n",
    "#This can also be added to the dictionary spacy, and can be updated as needed\n",
    "heading_dictionary = pd.read_csv(\"../Lower_big_headings_dictionary.csv\")\n",
    "heading_dictionary.drop_duplicates(inplace = True)\n",
    "experience_headings = heading_dictionary[heading_dictionary.Label == \"experience\"]\n",
    "skills_headings = heading_dictionary[heading_dictionary.Label == \"skills\"]\n",
    "education_headings = heading_dictionary[heading_dictionary.Label == \"education\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import fitz\n",
    "'''\n",
    "read_pdf_resume: get the path and the name of the pdf resume and read all the pages into a string variable\n",
    "Parameter:  pdf_document: a full path to a pdf resume\n",
    "Return: text: all the text in all pages of the pdf document\n",
    "'''\n",
    "def read_pdf_resume(pdf_document):\n",
    "    try:\n",
    "        doc = fitz.open(pdf_document) \n",
    "        text = ''\n",
    "        for i, page_n in enumerate(doc.pages()):\n",
    "            page = page_n.getText(\"text\")\n",
    "            text += \" \"+page\n",
    "    except :\n",
    "        return ('')\n",
    "    else:\n",
    "        return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "initial_cleaning:  split documents using return controler \\n; remove empty lines\n",
    "Parameter: doc_2_clean, a string variable containing the whole resume of a given person\n",
    "'''\n",
    "\n",
    "#is_symbol: check if the string has only at most 2 characters (so it may be a symbol)\n",
    "def is_symbol(s):\n",
    "    res = s.strip()\n",
    "    l = list(s)\n",
    "    if (len(l) < 3):\n",
    "        return(True)\n",
    "    else:\n",
    "        return(False)\n",
    "def remove_symbols(text_l):\n",
    "    tmp = [x for x in text_l if not is_symbol(x)]\n",
    "    return(tmp)\n",
    "def initial_cleaning(doc_2_clean):\n",
    "    text2 = doc_2_clean.split(\"\\n\")\n",
    "    text2 = [i.strip() for i in text2]\n",
    "    text2 = list(filter(lambda x: x != '', text2))\n",
    "    text2 = remove_symbols(text2)\n",
    "    return (text2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "s = \"Institute for Educational Sciences Fellow at University of Pennsylvania, Philadelphia, PA 2004-Present\"\n",
    "'''\n",
    "get_date:  Extract dates from resume.  This is specifically for extracting the date in job experience \n",
    "( a range of 2 dates).  For education, one can just use Spicy to extract the date \n",
    "parameters:\n",
    "s : a string\n",
    "'''\n",
    "\n",
    "def get_date(s):\n",
    "    #Covers 90% of date patters\n",
    "    date_pattern = \"(\\w{3,9}\\.*\\s+|[0-9]{2}\\/)\\d{4}\\s*(\\-|\\–|To|to|TO)\\s*((P|p|C|c)|(\\w{3,9}\\.*\\s+|[0-9]{2}\\/)\\d{4})\"\n",
    "    date_pattern2 = \"\\d{4}\\s*(\\-|\\–|To|to|TO)\\s*(\\d{4}|(P|p|C|c))\"\n",
    "    data_pattern3 =\"\\d{4}\\-\\d{2}\\s*(\\-|\\–|To|to|TO)\\s*((P|p|C|c)|\\d{4}\\-\\d{2})\"\n",
    "    tp = re.search(date_pattern,s)\n",
    "    if not tp:\n",
    "        tp2 = re.search(date_pattern2,s)\n",
    "        if not tp2:\n",
    "            tp3 = re.search(data_pattern3,s)\n",
    "            if tp3:\n",
    "                start = tp3.span()[0]\n",
    "                end  = tp3.span()[1]\n",
    "                return [start,end, tp3.string[start:end]] \n",
    "            else:\n",
    "                return [0,0,\"\"]\n",
    "        if tp2:\n",
    "            start = tp2.span()[0]\n",
    "            end  = tp2.span()[1]\n",
    "            return [start,end, tp2.string[start:end]]\n",
    "        \n",
    "    else:\n",
    "        print(\"pattern1\")\n",
    "        start = tp.span()[0]\n",
    "        end  = tp.span()[1]\n",
    "        return [start,end, tp.string[start:end]]\n",
    "\n",
    "'''\n",
    "get_date_and_remove_it_from_title:  find the date and remove it.\n",
    "'''    \n",
    "def get_date_and_remove_it_from_title(st):\n",
    "    s = st.strip()\n",
    "    start,end, date_s = get_date(s)\n",
    "    print(s)\n",
    "    if date_s:\n",
    "        if start == 0:\n",
    "            pat = r'(P|p|C|c)$'             \n",
    "            match = re.search(pat, date_s)\n",
    "            if match:\n",
    "                print(\"found\")\n",
    "                end = end + 7\n",
    "                s = s[end:]\n",
    "            else:\n",
    "                s = s[len(date_s):].strip()\n",
    "        else:\n",
    "            s = s[:start-1]\n",
    "    else:\n",
    "        date_s = \"\"\n",
    "    return date_s,s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 22, 'Sept. 2012 – Aug. 2016']"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_date(\"Sept. 2012 – Aug. 2016\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "'''\n",
    "clean_title_df: initial cleaning of the titles.  Some titles will have tabs instead of space, or some non-digit \n",
    "characters\n",
    "parameters:\n",
    "s: string\n",
    "'''\n",
    "def clean_title_df(s):\n",
    "    pattern1 = \"\\|\\s|(\\:)$\"\n",
    "    pattern2 = \"^[a-z]\\.\"\n",
    "    s = s.replace(\"\\t\",\" \")\n",
    "    s = s.replace(u'\\xa0', u' ')\n",
    "    s = re.sub(pattern2,\"\",s)\n",
    "    s =  re.sub(pattern1, \"\", s)\n",
    "    s = re.sub(\"^[:xdigit:]\",\"\", s)\n",
    "    s = s.strip()\n",
    "    return(s) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if check_if_potential_title(\"UNIVERSITY OF COLORADO BOULDER | THIS IS \"):\\n    print(\"Found\")'"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "gather_headings:  get the headings name, and their location for a given resume\n",
    "Parameters:  doc_list: resume as a list of strings; resume_name: the resume file name\n",
    "Return: blocks_df: a pandas dataframe with the resume name, position of a heading, and its name\n",
    "tmp check_if_headings(block)\n",
    "'''\n",
    "def check_if_potential_title(s):\n",
    "    s = s.strip()\n",
    "    start,end, date_s =  get_date(s)\n",
    "    if date_s:\n",
    "        return(True)\n",
    "    if re.search(\"^[0-9]{4}\\Z\",s):\n",
    "        return(True)\n",
    "    pattern = \"^[A-Z]\\s[A-Z]\\s[A-Z]\\s\"\n",
    "    s = s.replace(\"\\t\",\" \")\n",
    "    s = s.replace(\"&\",\"\")\n",
    "    s = s.replace(\"|\",\"\")\n",
    "    if re.search(pattern,s):\n",
    "            return(True)\n",
    "    else:\n",
    "        tmp = s.split(\" \")\n",
    "        tmp = [x for x in tmp if not x == '']\n",
    "        tmp = [x.strip() for x in tmp]\n",
    "        if (len(tmp) == 1) and tmp[0][0].isupper():\n",
    "            if re.search(\"[a-z]+\\.$\",tmp[0]):\n",
    "                return(False)\n",
    "            else:\n",
    "                return(True)\n",
    "        \n",
    "        if (len(tmp) == 2) and (tmp[0][0].isupper()):\n",
    "             return(True)\n",
    "        elif (len(tmp) >= 3):\n",
    "            tmp = [x for x in tmp if x not in [\"of\",\"and\",\"for\",\"in\",\"at\"]]\n",
    "            if tmp[0].isupper():\n",
    "                return(True)\n",
    "            if tmp[0][0].isupper():\n",
    "                if tmp[1][0].isupper():\n",
    "                    return(True)\n",
    "                else:\n",
    "                    return(False)\n",
    "            else:\n",
    "                return(False)\n",
    "        else:\n",
    "            return(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_if_potential_title(\"November 2015 to November 2016\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%        \n"
    }
   },
   "outputs": [],
   "source": [
    "def multiple_replace(string, reps, re_flags = 0):\n",
    "    \"\"\" Transforms string, replacing keys from re_str_dict with values.\n",
    "    reps: dictionary, or list of key-value pairs (to enforce ordering;\n",
    "          earlier items have higher priority).\n",
    "          Keys are used as regular expressions.\n",
    "    re_flags: interpretation of regular expressions, such as re.DOTALL\n",
    "    \"\"\"\n",
    "    if isinstance(reps, dict):\n",
    "        reps = reps.items()\n",
    "    pattern = re.compile(\"|\".join(\"(?P<_%d>%s)\" % (i, re_str[0])\n",
    "                                  for i, re_str in enumerate(reps)),\n",
    "                         re_flags)\n",
    "    return pattern.sub(lambda x: reps[int(x.lastgroup[1:])][1], string) \n",
    "\n",
    "'''\n",
    "check_number_uppercases_words:  check if the words in a line are upper case.  However, it makes sure to \n",
    "remove digits, some stopwords, that are lower cased in a title.  This function is used after the first pass of \n",
    "extracting titles from a resume.  \n",
    "Parameters:\n",
    "s: string\n",
    "Return:  True if a true title, else it returns false'''\n",
    "\n",
    "def check_number_uppercases_words(s):\n",
    "    replacements = [(\"\\t\", \"\"), (\"&\", \"\"),(\"\\/\" , \"\"),(\":\",\"\"),(\",\",\"\"),(\"-\",\" \"), (\" for \", \" \"),\n",
    "                    (\"–\" , \"\"),(\" at \",\" \"),(\" of \",\" \"),(\" in \",\" \"),(\" to \",\" \"),(\" and \",\" \"),(\"[0-9]\",\"\")]\n",
    "    s = multiple_replace(s, replacements)\n",
    "    tmp = s.split(\" \")\n",
    "    tmp = [x.strip() for x in tmp if x != \" \"]\n",
    "    tmp = [x for x in tmp if x]\n",
    "    upper_val = [x for x in tmp if  x[0].isupper()]\n",
    "    if (len(tmp) <= 2 & len(upper_val) == 1):\n",
    "        return(True)\n",
    "    elif len(tmp) == len(upper_val):\n",
    "        return(True)\n",
    "    else:\n",
    "        return(False) \n",
    "\n",
    "'''\n",
    "gather_headings:  get all the headings (titles) from the resume.\n",
    "Paramerters:\n",
    "  doc_list:  reading pdf to text result in a text with return lines, so a split result in a list of strings\n",
    "  resume_name: the file name of the resume\n",
    "  \n",
    "Returns:\n",
    "  blocks_df: a pandas df\n",
    "'''   \n",
    "def gather_headings(doc_list, resume_name):\n",
    "    blocks_df = pd.DataFrame()\n",
    "    for i,block in enumerate(doc_list):\n",
    "        block = clean_title_df(block)\n",
    "        tmp = block.split()\n",
    "        if len(tmp) == 1:\n",
    "            block = block.strip()\n",
    "            if block[0].isupper():\n",
    "                tmp_df = pd.DataFrame({\"Resume_Name\": resume_name,\"Block_Pos\" : i, \"Block_Title\" : block},index = [i])\n",
    "                blocks_df = blocks_df.append(tmp_df)\n",
    "        elif check_if_potential_title(block):\n",
    "            tmp_df = pd.DataFrame({\"Resume_Name\": resume_name,\"Block_Pos\" : i, \"Block_Title\" : block},index = [i])\n",
    "            blocks_df = blocks_df.append(tmp_df)\n",
    "    blocks_df.reset_index()\n",
    "    tp = [ x for ix, x in blocks_df.iterrows() if check_number_uppercases_words(x.Block_Title)]\n",
    "    blocks_df = pd.DataFrame(tp)\n",
    "    #blocks_df.reset_index()\n",
    "    return(blocks_df)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def V2_gather_headings(doc_list, resume_name):\n",
    "    blocks_df = pd.DataFrame()\n",
    "    pattern2ignore = \"\\A([A-Z][a-z]{3,}\\s*){2,3}\\.\"\n",
    "    for i,block in enumerate(doc_list):\n",
    "        block = clean_title_df(block)\n",
    "        tmp = block.split()\n",
    "        if check_if_potential_title(block) and not re.search(pattern2ignore,block):\n",
    "            tmp_df = pd.DataFrame({\"Resume_Name\": resume_name,\"Block_Pos\" : i, \"Block_Title\" : block},index = [i])\n",
    "            blocks_df = blocks_df.append(tmp_df) \n",
    "    #blocks_df.reset_index()\n",
    "    tp = [ x for ix, x in blocks_df.iterrows() if check_number_uppercases_words(x.Block_Title)]\n",
    "    blocks_df = pd.DataFrame(tp)\n",
    "    #blocks_df.reset_index()\n",
    "    return(blocks_df)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create an nlp object\n",
    "from spacy.matcher import Matcher\n",
    "def maybe_company(s):\n",
    "    m = s.split()\n",
    "    if m[0].isupper():\n",
    "        return(True)\n",
    "    else:\n",
    "        return(False)\n",
    "    \n",
    "def get_date_or_company(s):\n",
    "    date_s = \"\"\n",
    "    company_s = \"\"\n",
    "    doc = nlp(s)\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"DATE\":\n",
    "            date_s = ent.text\n",
    "            if not date_s:\n",
    "                _,end,date_s = get_date(s)  \n",
    "        elif ent.label_ == \"ORG\":\n",
    "            company_s = ent.text\n",
    "    return(date_s,company_s)\n",
    "def extract_degree_level(s):\n",
    "    doc = nlp(s)\n",
    "    degree = \"\"\n",
    "    degree_type = \"\"\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"EDU\":\n",
    "            degree_type = ent.ent_id_\n",
    "            degree = ent.text\n",
    "            return degree, degree_type\n",
    "    return degree, degree_type \n",
    "def extract_all_info_degree(s):\n",
    "    degree_dict = {\"GPE\":\"\",\"ORG\":\"\",\"Bachelor\":\"\",\"Master\":\"\",\"Doctor\":\"\",\"Major\":\"\",\"DATE\":\"\"}\n",
    "    degree_dict[\"DATE\"], s = get_date_and_remove_it_from_title(s)\n",
    "    s = s.replace(\"Magna cum Laude\",\"\")\n",
    "    s = s.replace(\"cum Laude\",\"\")\n",
    "    if re.search(\"\\s(A|a)t\\s\",s):\n",
    "        tp = re.split(\"\\s+(A|a)t\\s+\",s)\n",
    "        l = len(tp)-1\n",
    "        degree_dict[\"ORG\"] = tp[l]\n",
    "        s= tp[0]\n",
    "    doc = nlp(s)\n",
    "    degree_c = 1\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"DATE\":\n",
    "            if not degree_dict[\"DATE\"]:\n",
    "                degree_dict[ent.label_] = ent.text\n",
    "                s = s.replace(ent.text,\"\")\n",
    "            \n",
    "        else:\n",
    "            if ent.label_ == \"EDU\":\n",
    "                degree_dict[ent.ent_id_] = ent.text\n",
    "                s = s.replace(ent.text,\"\")\n",
    "            elif ent.label_ == \"ORG\":\n",
    "                if not degree_dict[\"ORG\"]:\n",
    "                        degree_dict[\"ORG\"] = degree_dict[\"ORG\"]+\" | \"+ent.text\n",
    "                        s = s.replace(ent.text,\"\")\n",
    "            elif ent.label_ == \"GPE\":\n",
    "                if not degree_dict[\"GPE\"]:\n",
    "                        degree_dict[\"GPE\"] = ent.text\n",
    "                        s = s.replace(ent.text,\"\")\n",
    "            \n",
    "            else:\n",
    "                if ent.label_ in list(degree_dict.keys()):\n",
    "                        degree_dict[ent.label_] = ent.text\n",
    "                        s = s.replace(ent.text,\"\")\n",
    "    if not degree_dict[\"DATE\"]:\n",
    "        tp = re.search(\"\\s\\d{4}$\",s)\n",
    "        if tp:\n",
    "            degree_dict[\"DATE\"]= s[tp.start():]\n",
    "            s = s[:tp.start()]\n",
    "           \n",
    "            \n",
    "    if not degree_dict[\"GPE\"]:\n",
    "        degree_dict[\"GPE\"]= extract_city(s)\n",
    "        if degree_dict[\"GPE\"]:\n",
    "            l = len(degree_dict[\"GPE\"])\n",
    "            degree_dict[\"GPE\"] = degree_dict[\"GPE\"][l-1]\n",
    "            s = s.replace(degree_dict[\"GPE\"],\"\")\n",
    "        else:\n",
    "            degree_dict[\"GPE\"]= \"\"\n",
    "    if not degree_dict[\"Major\"]:\n",
    "        s = s.replace(\".\",\"\")\n",
    "        s = re.sub(\"\\,\",\"\",s)\n",
    "        s = s.strip()\n",
    "        if re.search(\"School|University|College|Institute\",s):\n",
    "            degree_dict[\"Major\"]= degree_dict[\"ORG\"]\n",
    "            degree_dict[\"ORG\"] = re.sub(\"[^a-zA-Z&\\s]\",\"\",s).strip()\n",
    "        else:  \n",
    "            tp = re.split(\"(IN|in|In)\",s)\n",
    "            if len(tp) > 1:\n",
    "                degree_dict[\"Major\"]= re.sub(\"[^[a-zA-Z&\\s]\",\"\",tp[len(tp)-1]).strip()\n",
    "            else:\n",
    "                degree_dict[\"Major\"]= s\n",
    "        \n",
    "    return degree_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WESTERN KENTUCKY UNIVERSITY, Bowling Green, KY | Bachelor of Arts – Economics & Political Science\n"
     ]
    }
   ],
   "source": [
    "#get_date_or_company(\"South Dakota State University, Brookings MA, Economics 2014\")\n",
    "s = \"WESTERN KENTUCKY UNIVERSITY, Bowling Green, KY | Bachelor of Arts – Economics & Political Science\"\n",
    "date_s,company_s = get_date_or_company(s)\n",
    "if not date_s:\n",
    "    date_s, s = get_date_and_remove_it_from_title(s)\n",
    "    if not date_s:\n",
    "        tp = re.search(\"\\s+\\d{4}$\",s)\n",
    "        if tp:\n",
    "            date_s = s[tp.start():]\n",
    "            s = s[:tp.start()]\n",
    "    else:\n",
    "        s = re.replace(date_s,s)\n",
    "else:\n",
    "    s = s.replace(date_s,\" \")\n",
    "if company_s:\n",
    "    s = s.replace(company_s,\" \")\n",
    "s = s.replace(\",\",\"\") \n",
    "s = s.strip()\n",
    "city_s = extract_city(s)\n",
    "if len(city_s)>= 1:\n",
    "    city_s = city_s[0]\n",
    "if city_s:\n",
    "    s = s.replace(city_s,\"\")\n",
    "degree, degree_type = extract_degree_level(s)\n",
    "if degree:\n",
    "    s = s.replace(degree,\"\")\n",
    "    s = s.strip()\n",
    "    major = s\n",
    "else:\n",
    "    s = s.strip()\n",
    "    major = s\n",
    "    \n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def get_degree_university_date(s):\n",
    "doc = nlp(\"South Dakota State University, Brookings MA, Economics 2014\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.label_,ent.text)'''\n",
    "#city_s = extract_city(\"Augustana University, Sioux Falls BA, Econ & Math 2012\")\n",
    "#print(major, \" * \",city_s,\" * \",degree, \" * \", company_s, \" * \",date_s)\n",
    "#s = \"Fordham University, New York City PhD, Economics In progress, ABD\"\n",
    "#extract_city(\"New York City\")\n",
    "def get_job_info(s):\n",
    "    found = False\n",
    "    found_date = False\n",
    "    job_dict = {\"DATE\":\"\",\"ORG\":\"\",\"GPE\":\"\",\"Job_Title\":\"\"}\n",
    "    job_dict[\"GPE\"] = extract_city(s)\n",
    "    if job_dict[\"GPE\"]:\n",
    "        l = len(job_dict[\"GPE\"])-1\n",
    "        job_dict[\"GPE\"] = job_dict[\"GPE\"][l]\n",
    "        s = s.replace(job_dict[\"GPE\"],\"\")\n",
    "    else:\n",
    "        job_dict[\"GPE\"] = \"\"\n",
    "    doc = nlp(s)\n",
    "    n = 1\n",
    "    for ent in doc.ents:\n",
    "        '''if not found:\n",
    "            start,end, job_title = list(get_job_title(ent.text))[0]\n",
    "            if job_title:\n",
    "                job_dict[\"Job_Title\"] = job_title\n",
    "                found = True'''\n",
    "        print(\"s \",s)\n",
    "        if ent.label_ == \"GPE\":\n",
    "            if not job_dict[\"GPE\"]:\n",
    "                job_dict[\"GPE\"] = ent.text\n",
    "                s = s.replace(ent.text,\"\")\n",
    "        elif ent.label_ == \"DATE\":\n",
    "            if n == 1:\n",
    "                job_dict[\"DATE\"] =  ent.text\n",
    "                s = s.replace(ent.text,\"\")\n",
    "                n += 1\n",
    "            else:\n",
    "                job_dict[\"DATE\"] = job_dict[\"DATE\"]+\" - \"+ent.text\n",
    "                s = s.replace(ent.text,\"\")\n",
    "            found_date = True\n",
    "        elif ent.label_ == \"ORG\":\n",
    "            job_dict[ent.label_] = job_dict[ent.label_]+\" : \"+ent.text\n",
    "            s = s.replace(ent.text,\"\")\n",
    "            \n",
    "    if not job_dict[\"DATE\"]:    \n",
    "        job_dict[\"DATE\"],s = get_date_and_remove_it_from_title(s)\n",
    "    \n",
    "    if not found:\n",
    "        s = s.replace(\".\",\"\")\n",
    "        s = re.sub(\"[A-Z]{2}\",\"\",s)\n",
    "        s = re.sub(\"[^a-zA-Z\\s]\",\"\",s)\n",
    "        job_dict[\"Job_Title\"] = s.strip()\n",
    "    if isinstance(job_dict[\"GPE\"],list):\n",
    "        job_dict[\"GPE\"] = \"\"\n",
    "    return job_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def extract_city(s):\n",
    "    places = geograpy3.get_place_context(text = s)\n",
    "    return (places.cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def count_n_POS(s):\n",
    "    tmp = s.split(\",\")\n",
    "    tp = nltk.pos_tag(nltk.word_tokenize(tmp[0]))\n",
    "    res =[val for i, val in tp]\n",
    "    res = set(res) \n",
    "    return(res)\n",
    "def is_phone_number(s):\n",
    "    res = re.sub(r'[^\\w^\\s]', '', s) \n",
    "    res = res.replace(' ',\"\")\n",
    "    l = list(res)\n",
    "    if res.isnumeric() and (len(l) >= 9):\n",
    "        return(True)\n",
    "    else:\n",
    "        return(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8 Director\n"
     ]
    }
   ],
   "source": [
    "#\"from find_job_titles import FinderAcora\"\n",
    "\n",
    "#s = 'SR. DATA PROCESSING SYSTEMS ANALYST'\n",
    "#Find Job Title\n",
    "def get_job_title(s):\n",
    "    f = re.search(\"(QA\\s|ASSISTANT|Assistant|ANALYST|Analyst|PRINCIPAL|Principal)\",s)\n",
    "    if f:\n",
    "        start, end = f.span(0)\n",
    "        title_s = f.string\n",
    "        print(start, end)\n",
    "        yield start, end, s\n",
    "    else:\n",
    "        s = s.title()\n",
    "        finder=FinderAcora()\n",
    "        result = finder.finditer(s)\n",
    "        try:\n",
    "            gen = iter(result)\n",
    "            it = next(gen)\n",
    "            start = it.start\n",
    "            end   = it.end\n",
    "            title_s = it.match\n",
    "            yield start, end, title_s\n",
    "        except RuntimeError:\n",
    "            #return start, end, title_s\n",
    "            yield 0,0,\"\"\n",
    "\n",
    "'''s = \"Five Corner Strategies, Senior Project Manager / Data Director 02/2018-03/2019 Washington, DC\"\n",
    "s= \"Research Assistant, Fordham University Econometrics 2014– Present\"\n",
    "s = \"Humana (Stars Data Analytics), Louisville, Ky. — Data Science Architect\"\n",
    "s = \"GRADUATE COURSE ASSISTANT\"\n",
    "a,b,c = get_job_title(s)\n",
    "print(a, b, c )'''\n",
    "a, b, c = list(get_job_title(\"Director of Client Success\"))[0]\n",
    "print(a, b, c )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Teach For America – High School STEM Teacher, Chicago, IL May 2011-December 2012\n",
    "#Or BOSTON POLICE DEPARTMENT – Boston, MA 2001 TO 2007\n",
    "'''Pattern if - exist.  In this case, we can have 2 possibilities, either \n",
    "the first value is the company or the second is the company'''\n",
    "s = \"2013-2017 Founder & President - Boston Quantitative Innovations Pennington, NJ\"\n",
    "'''If date ad city found than we can assume that we have the company ad the job title\n",
    "'''\n",
    "def get_city_and_remove_it(st):\n",
    "    city_s = extract_city(st)\n",
    "    if city_s:\n",
    "        city_s = city_s[len(city_s)-1]\n",
    "        matches = re.finditer(city_s, st)\n",
    "        matches_positions = [match.start() for match in matches]\n",
    "        matches_positions = matches_positions[len(matches_positions)-1]\n",
    "        s = st\n",
    "        s = s[:matches_positions-1]\n",
    "        print(\"Company \",s)\n",
    "        return city_s, s\n",
    "    else:\n",
    "        return \"\",st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%    \n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant-Google, Chicago, IL\n",
      "['Assistant', 'Google, Chicago, IL']\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'job Title': 'Assistant', 'Company': 'Google, Chicago, ', 'Dates': ''}"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In here we assume city and company after job description\n",
    "#but we have Company, City, KY. - Title\n",
    "\n",
    "'''\n",
    "CHECK IT OUT \n",
    "'''\n",
    "def get_title_company_AT(st,pattern_at):\n",
    "    tp = re.split(pattern_at,st)\n",
    "    tp = [x.strip() for x in tp if x]\n",
    "    tp = [x for x in tp if x not in [\"at\",\"At\"]]\n",
    "    job_title = tp[0]\n",
    "    city_s = extract_city(tp[1])\n",
    "    if city_s and re.search(\"\\,\",tp[1]):\n",
    "        tp_city = re.split(\"\\,\",tp[1])\n",
    "        print(tp_city)\n",
    "        company_s = tp_city[0]\n",
    "    return job_title, company_s\n",
    "\n",
    "def get_title_company_commma(st):\n",
    "    tp = re.split(punct,s)\n",
    "    tp = [x.strip() for x in tp if x]\n",
    "    tp = [x for x in tp if x not in [\",\",\"|\"]]\n",
    "    start, end, job_title = list(get_job_title(tp[0]))[0]\n",
    "    if end == 0:\n",
    "        job_title = tp[1]\n",
    "        company_s = tp[0]\n",
    "    else:\n",
    "        job_title = tp[0]\n",
    "        company_s = tp[1]\n",
    "    return job_title, company_s\n",
    "\n",
    "def get_work_heading(st,punct):\n",
    "    s = st.strip()\n",
    "    date_s, s = get_date_and_remove_it_from_title(s)\n",
    "    pattern_at = \"\\s+(at|At|AT)\\s+\"\n",
    "    pattern_comma = \"\\s*(\\,|\\||/)\\s+\"\n",
    "    pattern_under = \"\\s*(-|—\\|)\\s*\"\n",
    "    if re.search(pattern_at,s):\n",
    "        job_title, company_s = get_title_company_AT(s,pattern_at)\n",
    "    elif re.search(pattern_under,s):    \n",
    "        tp = re.split(punct,s)\n",
    "        tp = [x.strip() for x in tp if x]\n",
    "        tp = [x for x in tp if x not in [\"-\",\"—\",\"|\"]]\n",
    "        print(tp)\n",
    "        #print(len(tp),\"tp \" ,tp)\n",
    "        if len(tp)== 3 :\n",
    "            tp[1] = tp[len(tp)-1]\n",
    "        city_s, company_s = get_city_and_remove_it(tp[1])\n",
    "        if not city_s:\n",
    "            city_s, company_s = get_city_and_remove_it(tp[0])\n",
    "            job_title = tp[1]\n",
    "        if  city_s: \n",
    "            job_title = tp[0]\n",
    "          \n",
    "                    \n",
    "    else :\n",
    "        tp = re.split(pattern_comma,s)\n",
    "        print(tp)\n",
    "        tp = [x.strip() for x in tp if x]\n",
    "        tp = [x for x in tp if x not in [\",\",\"|\",\"/\"]]\n",
    "        start, end, job_title = list(get_job_title(tp[0]))[0]\n",
    "        if end == 0:\n",
    "            job_title = tp[1]\n",
    "            company_s = tp[0]\n",
    "        else:\n",
    "            job_title = tp[0]\n",
    "            company_s = tp[1]\n",
    "    job_dict = {\"job Title\" : job_title, \"Company\" : company_s,\"Dates\" : date_s }\n",
    "    return(job_dict)\n",
    "'''#s = \"2004-2008 Institute for Educational Sciences Fellow at University of Pennsylvania, Philadelphia, PA\"\n",
    "s = \"2011-2013 Director of Research & Evaluation at Camden Coalition of Healthcare Providers, Camden, NJ\"\n",
    "s = \"UNIVERSITY OF COLORADO BOULDER at GRADUATE COURSE ASSISTANT\"\n",
    "pattern1 = \"(\\s+(at|At)\\s+|\\s*(\\–|\\-|\\—|\\|)\\s*)\"\n",
    "pattern2 = \" at | At \"\n",
    "get_work_heading(s,pattern1)'''\n",
    "#tp = re.split(\"\\s*(–|-)\\s*\",s)\n",
    "#print(re.split(\"\\sat\\s\",\"this at is\"))\n",
    "#city_s = extract_city(s)\n",
    "\n",
    "pattern1 = \"(\\s+(at|At)\\s+|\\s*(\\–|\\-|\\—|\\|)\\s*)\"\n",
    "s = \"Assistant-Google, Chicago, IL\"\n",
    "get_work_heading(s,pattern1)\n",
    "#places = geograpy3.get_place_context(text = s)\n",
    "#re.split(\"\\s*(\\,|\\||/)\\s+\",s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is a function with no ']\n"
     ]
    }
   ],
   "source": [
    "tp = re.split(\",|\\|\",\"This is a function with no \")\n",
    "print(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant - Google, Chicago, IL\n",
      "\n",
      "MATCH HERE\n",
      "Assistant - Google, Chicago, IL\n",
      "['Assistant - Google', ',', 'Chicago', ',', 'IL']\n",
      "0 9\n",
      "{'job Title': 'Assistant - Google', 'Company': 'Chicago', 'Dates': ''}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('', '')"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"NRCC (National Republican Congressional Committee), Director of Analytics 03/2016-12/2017 Washington, DC\"\n",
    "s2 = \"Director of Analytics at NRCC (National Republican Congressional Committee),  Washington, DC 03/2016-12/2017\"\n",
    "\n",
    "'''RETHINK THIS'''\n",
    "def get_Title_Co_Commas(st):\n",
    "    job_title = \"\"\n",
    "    company_s = \"\"\n",
    "    date_s = \"\"\n",
    "    s = st.strip()\n",
    "    date_s, s = get_date_and_remove_it_from_title(s)\n",
    "    print(date_s)\n",
    "    matches = re.finditer(\"(\\s+(a|A)t\\s+|\\s*(\\—|\\-)\\s*)\", s)\n",
    "    matches_positions = [match.start() for match in matches]\n",
    "    if matches_positions:\n",
    "        pattern1 = \"(\\s+(at|At)\\s+|\\s*(\\–|\\-|\\—|\\|)\\s*)\"\n",
    "        res = get_work_heading(s,pattern1)\n",
    "        job_title = res[\"job Title\"]\n",
    "        company_s = res[\"Company\"]\n",
    "    else:\n",
    "        matches = re.finditer(\",|\\|\", s)\n",
    "        matches_positions = [match.start() for match in matches]\n",
    "       \n",
    "        if matches_positions:\n",
    "            tp = re.split(\"(,|\\|)\",s) \n",
    "            tp = [x for x in tp if x not in [\",\",\"|\"]]\n",
    "            print(\" SSSS \",s, len(tp))\n",
    "            print(\" TPP \",tp)\n",
    "            if len(tp) == 2:\n",
    "                _,company_s = get_date_or_company(tp[0])\n",
    "                if company_s:\n",
    "                    start,end,job_title = list(get_job_title(tp[1]))[0]\n",
    "                else:\n",
    "                    start,end,job_title = list(get_job_title(tp[0]))[0]\n",
    "                    _, company_s = get_city_and_remove_it(tp[1])\n",
    "                        \n",
    "            \n",
    "                \n",
    "        else:\n",
    "            start,end,job_title = list(get_job_title(s))[0]\n",
    "            if end == 0:\n",
    "                company_s = s\n",
    "                \n",
    "    job_dict = {\"job Title\" : job_title, \"Company\" : company_s,\"Dates\" : date_s }\n",
    "    return job_dict\n",
    "#s = \"Humana (Stars Data Analytics), Louisville, Ky. — Data Science Architect\"\n",
    "#print(get_Title_Co_Commas(\"Teacher , Google\"))\n",
    "print(get_Title_Co_Commas(\"Assistant - Google, Chicago, IL\"))\n",
    "#print(get_work_heading(s,pattern1))\n",
    "get_date_or_company(\"Assistant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def is_place(s):\n",
    "\n",
    "    if extract_city(s) == []:\n",
    "        return (False)\n",
    "    else:\n",
    "        return (True)\n",
    "def is_email(s):\n",
    "    pat = r'.*?@(.*)\\..*'  \n",
    "    pat = r'[\\w.-]+@[\\w.-]+'\n",
    "    match = re.search(pat, s)\n",
    "    if not match:\n",
    "        return (False)\n",
    "    else:\n",
    "        return(True)\n",
    "    \n",
    "def is_github_or_linkedIn(s):\n",
    "    pattern2 = '(g|G)ithub|(l|L)inked(i|I)n'\n",
    "    if  any(re.findall(pattern2, s, re.IGNORECASE)):\n",
    "        return(True)\n",
    "    else:\n",
    "        return(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_heading_position(resume_df, chosen_heading):\n",
    "    tmp_l = [x.strip() for x in chosen_heading]\n",
    "    for i, item in enumerate(resume_df.Block_Title):\n",
    "        if str(item).lower() in tmp_l:\n",
    "            return (int(i))\n",
    "    return(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def V2_get_start_and_end_experience(resume_df,experience_headings):\n",
    "    global heading_dictionary\n",
    "    experience_headings = heading_dictionary[heading_dictionary.Label == \"experience\"]\n",
    "    skills_headings = heading_dictionary[heading_dictionary.Label == \"skills\"]\n",
    "    education_headings = heading_dictionary[heading_dictionary.Label == \"education\"]\n",
    "    resume_df = resume_df.reset_index()\n",
    "    pos = find_heading_position(resume_df, experience_headings.Block_Title)\n",
    "    \n",
    "    if (pos == -1):\n",
    "        print(\"Please add the name of the Experience heading to big_heading_dictionary\")\n",
    "        return (0,0)\n",
    "    else:\n",
    "        start_t = resume_df.Block_Pos.iloc[pos]+1\n",
    "        pos = find_heading_position(resume_df, education_headings.Block_Title)\n",
    "        \n",
    "        if (pos == -1):\n",
    "            print(\"Please add the heading to Education to the big_headings_dictionary.csv\")\n",
    "            education_pos = -1 \n",
    "        else:\n",
    "            education_pos = resume_df.Block_Pos.iloc[pos]+1\n",
    "        pos = find_heading_position(resume_df, skills_headings.Block_Title)\n",
    "        \n",
    "        if (pos == - 1):\n",
    "            skills_pos = -1\n",
    "        else:\n",
    "            skills_pos = resume_df.Block_Pos.iloc[pos]+1\n",
    "                \n",
    "        if ( start_t < education_pos) & (start_t < skills_pos):\n",
    "            end_extract_pos = min(education_pos,skills_pos)\n",
    "        elif ( start_t > education_pos) &(start_t < skills_pos):\n",
    "            end_extract_pos = skills_pos\n",
    "        elif ( start_t < education_pos) & (start_t > skills_pos):\n",
    "            end_extract_pos = education_pos\n",
    "        else: \n",
    "            end_extract_pos = len(resume_l)\n",
    "        return(start_t,end_extract_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Detect start of an experience (Company name, location, position, place)\n",
    "\n",
    "def V2_detect_start_experience(text_l,pos,n):\n",
    "    global keep_Experience_headings\n",
    "    s = text_l[pos]\n",
    "    s = s.replace(\"\\t\",' ')\n",
    "    i = pos\n",
    "    not_start = True\n",
    "    while not_start:\n",
    "        _,_,date_s = get_date(s)\n",
    "        if (not is_symbol(s) and (len(count_n_POS(s)) < 4) and i < n) or check_if_potential_title(s):\n",
    "            if (i >= len(text_l)) :\n",
    "                not_start = False\n",
    "            else:\n",
    "                keep_Experience_headings =keep_Experience_headings.append(pd.DataFrame({\"Exp_Heading\" : s}, index=[0]), ignore_index = True)\n",
    "                s = text_l[i]\n",
    "                s = s.replace(\"\\t\",' ')\n",
    "                \n",
    "            i += 1\n",
    "        elif(i >= n):\n",
    "            not_start = False\n",
    "        elif (len(count_n_POS(s)) >= 4):\n",
    "            not_start = False\n",
    "        \n",
    "        \n",
    "    return (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def V3_detect_start_experience(text_l,pos,n):\n",
    "    s = text_l[pos]\n",
    "    pos_l = pos\n",
    "    start_pos =  next(iter(resume_df[resume_df['Block_Pos']== pos_l-1].index), -1)\n",
    "    while start_pos:\n",
    "        pos_l += 1\n",
    "        start_pos = next(iter(resume_df[resume_df['Block_Pos']== pos_l-1].index), -1)\n",
    "        if pos_l >= n:\n",
    "            start_pos = False\n",
    "    return(pos_l-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Software Engineer',\n",
       " 'HeavyWater Inc -  Philadelphia, PA - 2017-03 - Present',\n",
       " '• Responsible for automation of services provided through AWS (Lambda, EC2, SWF) in Document Processing',\n",
       " 'Virtual Assistant.',\n",
       " '• Working on DevOps principles to improve system performance at different levels in existing infrastructure.',\n",
       " '• Responsible for operations and monitoring of production system.',\n",
       " '• Working on improvement of existing machine learning algorithms to extract data points accurately.',\n",
       " 'Machine Learning Engineer',\n",
       " 'Lumidatum Inc - 2016-11 - 2017-02']"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(start_t)\n",
    "end = V3_detect_start_experience(resume_l, start_t, start_t+10)\n",
    "resume_l[start_t:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Extract the paragraph or block with the experience \n",
    "\n",
    "def extract_experience(text_l,pos,n):\n",
    "    \n",
    "    i = pos\n",
    "    not_end = True\n",
    "    experience_txt = \"\"\n",
    "    #Is lower, and number of words is more than \n",
    "    while not_end:\n",
    "        if i >= n:\n",
    "            not_end = False\n",
    "        else:\n",
    "            s = text_l[i]\n",
    "            s = s.replace(\"\\t\",' ')\n",
    "            if check_if_potential_title(s) :\n",
    "                not_end = False\n",
    "            else: \n",
    "                if is_github_or_linkedIn(s) or is_email(s) or is_phone_number(s):\n",
    "                    i = n\n",
    "                    not_end = False\n",
    "                else:\n",
    "                    experience_txt = experience_txt + \"\\n\"+ s\n",
    "            i += 1\n",
    "    return (experience_txt, i-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_experiences(resume_l,start_t,end_extract_pos):\n",
    "\n",
    "    experience_df = pd.DataFrame()\n",
    "    keep_extracting_exp = True\n",
    "    len_resume = end_extract_pos\n",
    "    start_pos = start_t\n",
    "    counter = 1\n",
    "    while keep_extracting_exp:\n",
    "        start_exp = V2_detect_start_experience(resume_l,start_pos,len_resume)\n",
    "        if start_exp == len_resume - 1:\n",
    "            keep_extracting_exp = False\n",
    "        #break\n",
    "        else:\n",
    "            exp_txt,end_exp = extract_experience(resume_l,start_exp-1,len_resume)\n",
    "            start_pos = end_exp\n",
    "            experience_df = experience_df.append({\"Experiences\" : exp_txt,\"Counter\": counter},ignore_index = True)\n",
    "            counter += 1\n",
    "            if end_exp >= len_resume - 1:\n",
    "                keep_extracting_exp = False\n",
    "            \n",
    "    return(experience_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_headings(resume_df):\n",
    "    for index, row in resume_df.iterrows():\n",
    "        degree,degree_type = extract_degree_level(row[\"Block_Title\"])\n",
    "        if degree:\n",
    "            \n",
    "            degree_info = extract_all_info_degree(row[\"Block_Title\"])\n",
    "            #\n",
    "            #    print(key, \" * \",index)\n",
    "            for key, val in degree_info.items():\n",
    "                resume_df.loc[index,key] = val\n",
    "        else:\n",
    "            job_info = get_job_info(row[\"Block_Title\"])\n",
    "            print(\" JOB INFO \", job_info)\n",
    "            for key, val in job_info.items():\n",
    "                resume_df.loc[index,key] = val\n",
    "            #tp = [1 for x in list(job_info.values()) if x]\n",
    "            #if tp:\n",
    "             #   for key, val in job_info.items():\n",
    "             #       print(key, \" * \",index)\n",
    "             #       resume_df.iloc[index,key] = val\n",
    "    return resume_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern1\n",
      "pattern1\n",
      "pattern1\n",
      "pattern1\n",
      "pattern1\n",
      "Please add the heading to Education to the big_headings_dictionary.csv\n"
     ]
    }
   ],
   "source": [
    "path_name = \"../CFDS/\"\n",
    "resume_name = \"82143925.pdf\"\n",
    "\n",
    "keep_Experience_headings = pd.DataFrame()\n",
    "pdf_document = path_name+ resume_name \n",
    "text = read_pdf_resume(pdf_document)\n",
    "resume_l = initial_cleaning(text)\n",
    "resume_df = V2_gather_headings(resume_l,resume_name)\n",
    "start_t, end_extract_pos = V2_get_start_and_end_experience(resume_df,experience_headings)\n",
    "resume_df.reset_index(inplace=True,drop=True)\n",
    "resume_df2 = tag_headings(resume_df)\n",
    "resume_df2.loc[resume_df2.Block_Pos < start_t, \"Job_Title\"] = \"\"\n",
    "\n",
    "#total_experience = get_all_experiences(resume_l,start_t,end_extract_pos)\n",
    "#resume_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes2process = pd.read_csv(\"../CFDS_Resume_2_Process.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dalila.benachenhou/Documents/HSS/HSS_Resumes'"
      ]
     },
     "execution_count": 1014,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern1\n",
      "pattern1\n",
      "pattern1\n",
      "pattern1\n",
      "s  JIALU HUANG\n",
      "HUANG\n",
      " JOB INFO  {'DATE': '', 'ORG': ' : JIALU', 'GPE': '', 'Job_Title': 'G'}\n",
      "EDUCATION\n",
      " JOB INFO  {'DATE': '', 'ORG': '', 'GPE': '', 'Job_Title': 'N'}\n",
      "s   College London, United Kingdom.\n",
      "s   College London, United Kingdom.\n",
      "College London, United Kingdom.\n",
      " JOB INFO  {'DATE': '', 'ORG': '', 'GPE': 'Imperial', 'Job_Title': 'College London United Kingdom'}\n",
      "s  September 2018 - September 2019\n",
      " JOB INFO  {'DATE': 'September 2018 - September 2019', 'ORG': '', 'GPE': '', 'Job_Title': ''}\n",
      "MSc Statistics\n",
      " DEGREE INFO  {'GPE': '', 'ORG': '', 'Bachelor': '', 'Master': 'MSc', 'Doctor': '', 'Major': 'Statistics', 'DATE': ''}\n",
      "s  The  of Edinburgh, United Kingdom.\n",
      "s  The  of Edinburgh, United Kingdom.\n",
      "The  of Edinburgh, United Kingdom.\n",
      " JOB INFO  {'DATE': '', 'ORG': '', 'GPE': 'University', 'Job_Title': 'The  of Edinburgh United Kingdom'}\n",
      "s  September 2016-July 2018\n",
      " JOB INFO  {'DATE': 'September 2016-July 2018', 'ORG': '', 'GPE': '', 'Job_Title': ''}\n",
      "Bachelor of Mathematics and Statistics\n",
      " DEGREE INFO  {'GPE': '', 'ORG': '', 'Bachelor': 'Bachelor of Mathematics', 'Master': '', 'Doctor': '', 'Major': 'and Statistics', 'DATE': ''}\n",
      "s  South  University of Technology, Guangzhou, .\n",
      "s  , Guangzhou, .\n",
      ", Guangzhou, .\n",
      " JOB INFO  {'DATE': '', 'ORG': ' : South  University of Technology', 'GPE': 'China', 'Job_Title': 'Guangzhou'}\n",
      "s  September 2014 - July 2018\n",
      " JOB INFO  {'DATE': 'September 2014 - July 2018', 'ORG': '', 'GPE': '', 'Job_Title': ''}\n",
      "Bachelor of Mathematics and Applied Mathematics\n",
      " DEGREE INFO  {'GPE': '', 'ORG': '', 'Bachelor': 'Bachelor of Mathematics', 'Master': '', 'Doctor': '', 'Major': 'and Applied Mathematics', 'DATE': ''}\n",
      "s  Overall Percentage: 83\n",
      "Overall Percentage: 83\n",
      " JOB INFO  {'DATE': '', 'ORG': '', 'GPE': '', 'Job_Title': 'Overall Percentage'}\n",
      "WORK EXPERIENCE\n",
      " JOB INFO  {'DATE': '', 'ORG': '', 'GPE': '', 'Job_Title': ''}\n",
      "s   Telecom Guangdong Branch, Guangzhou, . WSSC Internship\n",
      "s   Telecom Guangdong Branch, Guangzhou, . WSSC Internship\n",
      "Telecom Guangdong Branch, Guangzhou, . WSSC Internship\n",
      " JOB INFO  {'DATE': '', 'ORG': '', 'GPE': 'China', 'Job_Title': 'Telecom Guangdong Branch Guangzhou   Internship'}\n",
      "s  August 2017\n",
      " JOB INFO  {'DATE': 'August 2017', 'ORG': '', 'GPE': '', 'Job_Title': ''}\n"
     ]
    }
   ],
   "source": [
    "all_job_titles = pd.DataFrame()\n",
    "path_name = \"../CFDS/\"\n",
    "resumes2process = pd.read_csv(\"../CFDS_Resume_2_Process.csv\")\n",
    "pdf_files = resumes2process.CFDS_Resume\n",
    "for resume_name in pdf_files:\n",
    "    keep_Experience_headings = pd.DataFrame()\n",
    "    pdf_document = path_name+ resume_name \n",
    "    text = read_pdf_resume(pdf_document)\n",
    "    if text:\n",
    "        resume_l = initial_cleaning(text)\n",
    "        resume_df = V2_gather_headings(resume_l,resume_name)\n",
    "        if resume_df.empty:\n",
    "            print(\"No Headings\")\n",
    "        else:\n",
    "            start_t, end_extract_pos = V2_get_start_and_end_experience(resume_df,experience_headings)\n",
    "            resume_df.reset_index(inplace=True,drop=True)\n",
    "            resume_df2 = tag_headings(resume_df)\n",
    "            resume_df2.loc[resume_df2.Block_Pos < start_t, \"Job_Title\"] = \"\"\n",
    "            all_job_titles = all_job_titles.append(resume_df2,ignore_index = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resume_Name</th>\n",
       "      <th>Block_Pos</th>\n",
       "      <th>Block_Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>0</td>\n",
       "      <td>Rohit Wason</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>5</td>\n",
       "      <td>RECENT EXPERIENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>7</td>\n",
       "      <td>Science Architect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>8</td>\n",
       "      <td>2018 - Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>11</td>\n",
       "      <td>Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>13</td>\n",
       "      <td>Engineer/Architect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>14</td>\n",
       "      <td>2014 - Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>22</td>\n",
       "      <td>Enterprise Architect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>23</td>\n",
       "      <td>2011 - 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>27</td>\n",
       "      <td>2010 - 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>30</td>\n",
       "      <td>2005 - 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>33</td>\n",
       "      <td>TOOLS I LOVE USING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>37</td>\n",
       "      <td>HOBBIES &amp; INTERESTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>43</td>\n",
       "      <td>STRENGTHS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>47</td>\n",
       "      <td>PAST EXPERIENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>48</td>\n",
       "      <td>1997 - 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>50</td>\n",
       "      <td>EDUCATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>51</td>\n",
       "      <td>Bachelor of Science, Delhi University, Delhi, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>52</td>\n",
       "      <td>1994 - 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>55</td>\n",
       "      <td>Diploma in Information Technology, Tata Infote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>57</td>\n",
       "      <td>1995 - 1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>60</td>\n",
       "      <td>PUBLIC TALKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>61</td>\n",
       "      <td>Superintelligence, Humana, Louisville, Ky.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>62</td>\n",
       "      <td>Feb 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>69</td>\n",
       "      <td>Nov 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>74</td>\n",
       "      <td>REFERENCES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>75</td>\n",
       "      <td>ANTONIO MELO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>78</td>\n",
       "      <td>JEFF HAWKINS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>82103515.pdf</td>\n",
       "      <td>81</td>\n",
       "      <td>JENNIFER REINHART</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Resume_Name  Block_Pos                                        Block_Title\n",
       "0   82103515.pdf          0                                        Rohit Wason\n",
       "1   82103515.pdf          5                                  RECENT EXPERIENCE\n",
       "2   82103515.pdf          7                                  Science Architect\n",
       "3   82103515.pdf          8                                     2018 - Present\n",
       "4   82103515.pdf         11                                              Guide\n",
       "5   82103515.pdf         13                                 Engineer/Architect\n",
       "6   82103515.pdf         14                                     2014 - Present\n",
       "7   82103515.pdf         22                               Enterprise Architect\n",
       "8   82103515.pdf         23                                        2011 - 2014\n",
       "9   82103515.pdf         27                                        2010 - 2011\n",
       "10  82103515.pdf         30                                        2005 - 2010\n",
       "11  82103515.pdf         33                                 TOOLS I LOVE USING\n",
       "12  82103515.pdf         37                                HOBBIES & INTERESTS\n",
       "13  82103515.pdf         43                                          STRENGTHS\n",
       "14  82103515.pdf         47                                    PAST EXPERIENCE\n",
       "15  82103515.pdf         48                                        1997 - 2005\n",
       "16  82103515.pdf         50                                          EDUCATION\n",
       "17  82103515.pdf         51  Bachelor of Science, Delhi University, Delhi, ...\n",
       "18  82103515.pdf         52                                        1994 - 1997\n",
       "19  82103515.pdf         55  Diploma in Information Technology, Tata Infote...\n",
       "20  82103515.pdf         57                                        1995 - 1998\n",
       "21  82103515.pdf         60                                       PUBLIC TALKS\n",
       "22  82103515.pdf         61         Superintelligence, Humana, Louisville, Ky.\n",
       "23  82103515.pdf         62                                           Feb 2017\n",
       "24  82103515.pdf         69                                           Nov 2016\n",
       "25  82103515.pdf         74                                         REFERENCES\n",
       "26  82103515.pdf         75                                       ANTONIO MELO\n",
       "27  82103515.pdf         78                                       JEFF HAWKINS\n",
       "28  82103515.pdf         81                                  JENNIFER REINHART"
      ]
     },
     "execution_count": 1005,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for newcol in ['DATE','ORG','GPE',\"Bachelor\",\"Master\",\"Doctor\",\"Job_Title\",\"Type\"]:\n",
    "    resume_df[newcol]= \"\"\n",
    "resume_df = resume_df.reset_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = resume_df.loc[start_t:end_extract_pos-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n"
     ]
    }
   ],
   "source": [
    "found_all= False\n",
    "\n",
    "start_pos =  next(iter(resume_df[resume_df['Block_Pos']==start_t-1].index), -1)\n",
    "continous_titles = pd.DataFrame()\n",
    "continous = True\n",
    "start_block = start_pos+1\n",
    "end_block = start_pos+1\n",
    "'''while continous:\n",
    "    if (resume_df.Block_Pos[end_block] - resume_df.Block_Pos[end_block-1]) == 1:\n",
    "        start_pos += 1\n",
    "    else:\n",
    "        continous = False'''\n",
    "print(start_block, end_block)\n",
    "#get_date_or_company(\"UNIVERSITY OF COLORADO BOULDER |GRADUATE COURSE\")\n",
    "#get_Title_Co_Commas(\"UNIVERSITY OF COLORADO BOULDER |GRADUATE COURSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found\n"
     ]
    }
   ],
   "source": [
    "tmp = resume_df.loc[start_t:end_extract_pos,:]\n",
    "check_number_uppercases_words(resume_df.Block_Title[13])\n",
    "if re.search(\"\\A([A-Z][a-z]{3,}\\s*){2,3}\\.\",resume_df.Block_Title[13]):\n",
    "    print(\"found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#resume_df = resume_df.reset_index()\n",
    "start_pos =  next(iter(resume_df[resume_df['Block_Pos']==start_t-1].index), -1)\n",
    "end_pos = next(iter(resume_df[resume_df['Block_Pos']==end_extract_pos-1].index), -1)\n",
    "if not end_pos:\n",
    "    end_pos,_ = resume_df.shape\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_pos = start_t-1\n",
    "for i in start_pos:end_extract_pos:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-314-72d4e4739b2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mend_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_pos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mcontinous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresume_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBlock_Pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mend_block\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mresume_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBlock_Pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mend_block\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mstart_pos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/allennlp/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/allennlp/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4374\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 4375\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   4376\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4377\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 8"
     ]
    }
   ],
   "source": [
    "found_all= False\n",
    "start_pos =  next(iter(resume_df[resume_df['Block_Pos']==start_t-1].index), -1)\n",
    "continous_titles = pd.DataFrame()\n",
    "continous = True\n",
    "start_block = start_pos\n",
    "end_block = start_pos\n",
    "while continous:\n",
    "    if (resume_df.Block_Pos[end_block] - resume_df.Block_Pos[end_block-1]) == 1:\n",
    "        start_pos += 1\n",
    "    else:\n",
    "        continous = False\n",
    "\n",
    "st = resume_df.loc[start_pos,\"Block_Title\"]\n",
    "tp = get_Title_Co_Commas(st)\n",
    "counter = 0\n",
    "missing_val = []\n",
    "for key, value in tp.items():\n",
    "    if value != \"\":\n",
    "        counter += 1\n",
    "    else:\n",
    "        missing_val.append(key)\n",
    "if counter == 2:\n",
    "    start_pos += 1\n",
    "    if (resume_df.Block_Pos[start_pos] - resume_df.Block_Pos[start_pos-1]) == 1:\n",
    "        st = resume_df.loc[start_pos,\"Block_Title\"]\n",
    "        if missing_val[0] == \"Dates\":\n",
    "            missing_date = \"True\"\n",
    "            date_s = get_date(s)\n",
    "            if date_s:\n",
    "                tp[\"Dates\"] = date_s\n",
    "            else:\n",
    "                start_pos +=1 \n",
    "                if (resume_df.Block_Pos[start_pos] - resume_df.Block_Pos[start_pos-1]) == 1:\n",
    "                        date_s = get_date(s)\n",
    "                        tp[\"Dates\"] = date_s\n",
    "        else:\n",
    "            tp[missing_val[0]] = st\n",
    "elif counter == 1:\n",
    "    print(\"Do nothing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_flags_2_resume_df(resume_df):\n",
    "    resume_df2 = resume_df.copy()\n",
    "    \n",
    "    for index, row in resume_df2.iterrows():\n",
    "        _,_,job_t = list(get_job_title(row[\"Block_Title\"]))[0]\n",
    "        date_d, company_s = get_date_or_company(row[\"Block_Title\"])\n",
    "        _,_,date_s = get_date(row.Block_Title)\n",
    "        city_s = extract_city(row[\"Block_Title\"])\n",
    "        degree_level = extract_degree_level(row[\"Block_Title\"])\n",
    "        if job_t:\n",
    "            resume_df2.loc[index,\"Job_Title\"] = 1\n",
    "            resume_df2.loc[index,\"Job_Title_txt\"] = job_t\n",
    "            print(\"title :\", job_t,row[\"Block_Pos\"])\n",
    "        if company_s:\n",
    "            resume_df2.loc[index,\"Company_Name\"] = 1\n",
    "            resume_df2.loc[index,\"Company_Name_txt\"] = company_s\n",
    "            print(\"Company: \",company_s, row.Block_Pos)\n",
    "        if date_s:\n",
    "            resume_df2.loc[index,\"Date_s\"] = 1\n",
    "            resume_df2.loc[index,\"Date_s_txt\"] = date_s\n",
    "            print(\"Date: \",date_s,row.Block_Pos)\n",
    "        if city_s:\n",
    "            resume_df2.loc[index,\"City_Name\"] = 1\n",
    "            resume_df2.loc[index,\"City_Name_txt\"] = city_s\n",
    "        if degree_level:\n",
    "            resume_df2.loc[index,\"Degree_level\"] = 1\n",
    "            resume_df2.loc[index,\"Degree_level_txt\"] = degree_level\n",
    "        if date_d and not date_s:\n",
    "            resume_df2.loc[index,\"Degree_Date\"] = 1\n",
    "            resume_df2.loc[index,\"Degree_Date_txt\"] = date_d\n",
    "    return resume_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index           int64\n",
       "Resume_Name    object\n",
       "Block_Pos       int64\n",
       "Block_Title    object\n",
       "DATE           object\n",
       "ORG            object\n",
       "GPE            object\n",
       "Bachelor       object\n",
       "Master         object\n",
       "Doctor         object\n",
       "Job_Title      object\n",
       "Type           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 903,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_headings(resume_df):\n",
    "    for index, row in resume_df.iterrows():\n",
    "        degree,degree_type = extract_degree_level(row[\"Block_Title\"])\n",
    "        if degree:\n",
    "            \n",
    "            degree_info = extract_all_info_degree(row[\"Block_Title\"])\n",
    "            #\n",
    "            #    print(key, \" * \",index)\n",
    "            for key, val in degree_info.items():\n",
    "                resume_df.loc[index,key] = val\n",
    "        else:\n",
    "            job_info = get_job_info(row[\"Block_Title\"])\n",
    "            print(\" JOB INFO \", job_info)\n",
    "            for key, val in job_info.items():\n",
    "                resume_df.loc[index,key] = val\n",
    "            #tp = [1 for x in list(job_info.values()) if x]\n",
    "            #if tp:\n",
    "             #   for key, val in job_info.items():\n",
    "             #       print(key, \" * \",index)\n",
    "             #       resume_df.iloc[index,key] = val\n",
    "    return resume_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 1000,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MICHAEL LAWRENCE SMITH, M.S.\n",
      " DEGREE INFO  {'GPE': '', 'ORG': '', 'Bachelor': '', 'Master': 'M.S.', 'Doctor': '', 'Major': 'MICHAEL LAWRENCE SMITH', 'DATE': ''}\n",
      "s  , Kentucky 40245\n",
      ", Kentucky 40245\n",
      " JOB INFO  {'DATE': '', 'ORG': '', 'GPE': 'Louisville', 'Job_Title': 'Kentucky'}\n",
      "s  Phone: 502-432-1542\n",
      "Phone: 502-432-1542\n",
      " JOB INFO  {'DATE': '', 'ORG': '', 'GPE': '', 'Job_Title': 'Phone'}\n",
      "WORK EXPERIENCE\n",
      " JOB INFO  {'DATE': '', 'ORG': '', 'GPE': '', 'Job_Title': ''}\n",
      "s  QC Analytical Team Lead                                                                                     November 2016-Current\n",
      "s  November 2016-Current\n",
      " JOB INFO  {'DATE': 'November 2016-Current', 'ORG': ' : QC Analytical Team Lead                                                                                     ', 'GPE': '', 'Job_Title': ''}\n",
      "s  Creosalus                                                                                                                         , Kentucky\n",
      "s  Creosalus                                                                                                                         , Kentucky\n",
      "Creosalus                                                                                                                         , Kentucky\n",
      " JOB INFO  {'DATE': '', 'ORG': '', 'GPE': 'Louisville', 'Job_Title': 'Creosalus                                                                                                                          Kentucky'}\n",
      "s   Control Documentation Chemist                                               November 2014-November 2016\n",
      "s    Chemist                                               November 2014-November 2016\n",
      " JOB INFO  {'DATE': 'November 2014-November 2016', 'ORG': ' : Control Documentation', 'GPE': 'Quality', 'Job_Title': 'Chemist'}\n",
      "s  Kremers Urban Pharmaceuticals                                                                                                    Seymour, \n",
      "Seymour,\n",
      " JOB INFO  {'DATE': '', 'ORG': ' : Kremers Urban Pharmaceuticals', 'GPE': 'Indiana', 'Job_Title': 'Seymour'}\n",
      "s  Assistant Professor                                                                                            August 2010- September 2014\n",
      "s  Assistant Professor                                                                                             September 2014\n",
      " JOB INFO  {'DATE': 'August 2010- - September 2014', 'ORG': '', 'GPE': '', 'Job_Title': 'Assistant Professor'}\n",
      "s  Focus: Medicinal Chemistry                                                                                                         Louisville, Kentucky\n",
      "s  Focus: Medicinal Chemistry                                                                                                         , Kentucky\n",
      "Focus: Medicinal Chemistry                                                                                                         , Kentucky\n",
      " JOB INFO  {'DATE': '', 'ORG': '', 'GPE': 'Louisville', 'Job_Title': 'Focus Medicinal Chemistry                                                                                                          Kentucky'}\n",
      "s  Sullivan , College of Pharmacy\n",
      "s   , College of Pharmacy\n",
      ",\n",
      " JOB INFO  {'DATE': '', 'ORG': ' : Sullivan : College of Pharmacy', 'GPE': 'University', 'Job_Title': ''}\n",
      "s  Research Assistant                                                                                                            May 2005- August 2010\n",
      " JOB INFO  {'DATE': 'August 2010', 'ORG': '', 'GPE': '', 'Job_Title': 'Research Assistant                                                                                                            May'}\n",
      "s   of Kentucky, College of Pharmacy                                                                          Lexington, Kentucky\n",
      "s   of Kentucky, College of Pharmacy                                                                          Lexington, Kentucky\n",
      "s   of Kentucky,                                                                           Lexington, Kentucky\n",
      "s   of Kentucky,                                                                           Lexington, Kentucky\n",
      "of Kentucky,                                                                           Lexington, Kentucky\n",
      " JOB INFO  {'DATE': '', 'ORG': ' : College of Pharmacy', 'GPE': 'University', 'Job_Title': 'of Kentucky                                                                           Lexington Kentucky'}\n",
      "EDUCATION AND TRAINING\n",
      " JOB INFO  {'DATE': '', 'ORG': '', 'GPE': '', 'Job_Title': 'N D'}\n",
      "s  Indiana University, School of Informatics and Computing\n",
      "s  , School of Informatics and Computing\n",
      ",\n",
      " JOB INFO  {'DATE': '', 'ORG': ' : Indiana University : School of Informatics and Computing', 'GPE': '', 'Job_Title': ''}\n",
      "M.S. Pharmaceutical Sciences\n",
      " DEGREE INFO  {'GPE': '', 'ORG': '', 'Bachelor': '', 'Master': 'M.S.', 'Doctor': '', 'Major': 'Pharmaceutical Sciences', 'DATE': ''}\n",
      "s  , Kentucky\n",
      ", Kentucky\n",
      " JOB INFO  {'DATE': '', 'ORG': '', 'GPE': 'Lexington', 'Job_Title': 'Kentucky'}\n",
      "Focus: Medicinal Chemistry and Drug Discovery\n",
      " JOB INFO  {'DATE': '', 'ORG': '', 'GPE': '', 'Job_Title': 'Focus Medicinal Chemistry and Drug Discovery'}\n",
      "s   of Kentucky, College of Pharmacy\n",
      "s   of Kentucky, College of Pharmacy\n",
      "of Kentucky,\n",
      " JOB INFO  {'DATE': '', 'ORG': ' : College of Pharmacy', 'GPE': 'University', 'Job_Title': 'of Kentucky'}\n",
      "B.S. Biological Sciences                                                                                                    Lexington, Kentucky\n",
      " DEGREE INFO  {'GPE': 'Lexington', 'ORG': '', 'Bachelor': 'B.S.', 'Master': '', 'Doctor': '', 'Major': 'Biological Sciences                                                                                                     Kentucky', 'DATE': ''}\n",
      "s   of Kentucky\n",
      "of Kentucky\n",
      " JOB INFO  {'DATE': '', 'ORG': '', 'GPE': 'University', 'Job_Title': 'of Kentucky'}\n",
      "Sample Data Science Projects\n",
      " JOB INFO  {'DATE': '', 'ORG': '', 'GPE': '', 'Job_Title': 'Sample Data Science Projects'}\n",
      "AWARDS\n",
      " JOB INFO  {'DATE': '', 'ORG': '', 'GPE': '', 'Job_Title': ''}\n",
      "s  Sullivan , College of Pharmacy                                                                                  Louisville, Kentucky\n",
      "s   , College of Pharmacy                                                                                  Louisville, Kentucky\n",
      "s   ,                                                                                   Louisville, Kentucky\n",
      "s   ,                                                                                   Louisville, Kentucky\n",
      ",                                                                                   Louisville, Kentucky\n",
      " JOB INFO  {'DATE': '', 'ORG': ' : Sullivan : College of Pharmacy', 'GPE': 'University', 'Job_Title': 'Louisville Kentucky'}\n",
      "s  SELECTED POSTER & ORAL PRESENTATIONS\n",
      "SELECTED  PRESENTATIONS\n",
      " JOB INFO  {'DATE': '', 'ORG': ' : POSTER & ORAL', 'GPE': '', 'Job_Title': 'S'}\n",
      "s  Abeer Al-Ghananeem, Michael L. Smith, Sara Baltzley                                                AACP Annual Meeting\n",
      "s  Abeer Al-Ghananeem, Michael L. Smith, Sara Baltzley                                                AACP Annual Meeting\n",
      "s  Abeer Al-Ghananeem, Michael L. Smith, Sara Baltzley                                                AACP Annual Meeting\n",
      "s  Abeer Al-Ghananeem, Michael L. Smith, Sara Baltzley                                                AACP Annual Meeting\n",
      "Abeer Al-Ghananeem, Michael L. Smith, Sara Baltzley                                                 Annual Meeting\n",
      " JOB INFO  {'DATE': '', 'ORG': ' : AACP', 'GPE': '', 'Job_Title': 'Abeer AlGhananeem Michael L Smith Sara Baltzley                                                 Annual Meeting'}\n",
      "s  , Texas\n",
      ", Texas\n",
      " JOB INFO  {'DATE': '', 'ORG': '', 'GPE': 'Grapevine', 'Job_Title': 'Texas'}\n",
      "s  Amanda Hornback, Leslie Clark, Gopalakrishna Pillai, Michael Smith                    ASHP Annual Meeting\n",
      "s  Amanda Hornback, Leslie Clark, Gopalakrishna Pillai, Michael Smith                    ASHP Annual Meeting\n",
      "s  Amanda Hornback, Leslie Clark, Gopalakrishna Pillai, Michael Smith                    ASHP Annual Meeting\n",
      "s  Amanda Hornback, Leslie Clark, Gopalakrishna Pillai, Michael Smith                    ASHP Annual Meeting\n",
      "s  Amanda Hornback, Leslie Clark, Gopalakrishna Pillai, Michael Smith                    ASHP Annual Meeting\n",
      " JOB INFO  {'DATE': 'Annual', 'ORG': '', 'GPE': '', 'Job_Title': 'Amanda Hornback Leslie Clark Gopalakrishna Pillai Michael Smith                      Meeting'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s  Las Vegas, \n",
      "Las Vegas,\n",
      " JOB INFO  {'DATE': '', 'ORG': '', 'GPE': 'Nevada', 'Job_Title': 'Las Vegas'}\n",
      "s  Michael L. Smith, Pallab Pahari, Jurgen Rohr                                                                ACS National Meeting\n",
      "s  Michael L. Smith, Pallab Pahari, Jurgen Rohr                                                                ACS National Meeting\n",
      "s  Michael L. Smith, , Jurgen Rohr                                                                ACS National Meeting\n",
      "s  Michael L. Smith, , Jurgen Rohr                                                                ACS National Meeting\n",
      "Michael L. Smith, , Jurgen Rohr                                                                ACS National Meeting\n",
      " JOB INFO  {'DATE': '', 'ORG': ' : Pallab Pahari', 'GPE': '', 'Job_Title': 'Michael L Smith  Jurgen Rohr                                                                S National Meeting'}\n",
      "s  San Francisco, \n",
      "San Francisco,\n",
      " JOB INFO  {'DATE': '', 'ORG': '', 'GPE': 'California', 'Job_Title': 'San Francisco'}\n",
      "PUBLICATIONS\n",
      " JOB INFO  {'DATE': '', 'ORG': '', 'GPE': '', 'Job_Title': ''}\n",
      "Shepherd MD, Nybo SE, Smith ML, Bosserman MA, Rohr J.\n",
      " DEGREE INFO  {'GPE': 'Nybo SE', 'ORG': '', 'Bachelor': '', 'Master': 'MA', 'Doctor': 'MD', 'Major': 'Shepherd   Smith ML Bosserman  Rohr J', 'DATE': ''}\n"
     ]
    }
   ],
   "source": [
    "resume_df2 = tag_headings(resume_df)\n",
    "resume_df2.loc[resume_df2.Block_Pos < start_t, \"Job_Title\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_df2.to_csv(\"CheckITOUT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manasa Reddy\n",
      "Big Data Engineer\n",
      "Work Experience\n",
      "Big Data Engineer\n",
      "SC Engineering Works\n",
      "November 2015 to November 2016\n",
      "Education\n",
      "Master of Science in Technology\n",
      "Jawaharlal Nehru Technological University\n",
      "Skills\n",
      "Additional Information\n",
      "TECHNICAL SKILLS\n",
      "Big Data Ecosystem: Hadoop, HDFS, YARN, MapReduce, Hive,\n",
      "Pig, Spark, Sqoop, Tez\n",
      "Languages: Python, SQL, Java, HTML,CSS.\n",
      "Databases: MS Access, SQL Server\n",
      "Editors: Eclipse\n",
      "Operating Systems: Windows, Unix\n",
      "Data Visualization: Tableau\n"
     ]
    }
   ],
   "source": [
    "resume_df.reset_index(inplace=True, drop=True)\n",
    "for index, row in resume_df.iterrows():\n",
    "    print(resume_df.loc[index,\"Block_Title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern1\n",
      "University of Minnesota Sept. 2012 – Aug. 2016\n",
      "University of Minnesota\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'GPE': '',\n",
       " 'ORG': 'University of Minnesota',\n",
       " 'Bachelor': '',\n",
       " 'Master': '',\n",
       " 'Doctor': '',\n",
       " 'Major': '',\n",
       " 'DATE': 'Sept. 2012 – Aug. 2016'}"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract_degree_level(\"Ph.D., 2008\")\n",
    "#get_date(\"Ph.D., 2008\")\n",
    "extract_all_info_degree(\"University of Minnesota Sept. 2012 – Aug. 2016\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_degree_level(\"Bachelors of Arts, Political Science - University of Minnesota\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title : Software Engineer 1\n",
      "title : Software Engineer 10\n",
      "Company:  HeavyWater Inc -   11\n",
      "Date:  2017-03 - P 11\n",
      "title : Learning Engineer 17\n",
      "Company:  Lumidatum Inc - 18\n",
      "Date:  2016-11 - 2017-02 18\n",
      "Company:  Master's in Computer Science 42\n",
      "Company:  University of Texas 43\n",
      "title : Computer Engineer 45\n",
      "Company:  Computer Engineering 45\n",
      "Company:  University of Pune -  Pune 46\n",
      "Company:  Python 49\n",
      "Company:  AWS 59\n",
      "Company:  Ubuntu 60\n"
     ]
    }
   ],
   "source": [
    "resume_df2 = add_flags_2_resume_df(resume_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dalila.benachenhou/anaconda3/envs/allennlp/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/dalila.benachenhou/anaconda3/envs/allennlp/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/dalila.benachenhou/anaconda3/envs/allennlp/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/Users/dalila.benachenhou/anaconda3/envs/allennlp/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/dalila.benachenhou/anaconda3/envs/allennlp/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/Users/dalila.benachenhou/anaconda3/envs/allennlp/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title : Software Engineer 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dalila.benachenhou/anaconda3/envs/allennlp/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company:  HeavyWater Inc -   11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dalila.benachenhou/anaconda3/envs/allennlp/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date:  2017-03 - P 11\n",
      "title : Learning Engineer 17\n",
      "Company:  Lumidatum Inc - 18\n",
      "Date:  2016-11 - 2017-02 18\n"
     ]
    }
   ],
   "source": [
    "#def get_start_end_continous_Rows(resume_df,)\n",
    "found_block = False\n",
    "\n",
    "resume_df2 = add_flags_2_resume_df(resume_df.query(\"index > \"+str(start_pos)+\" and index < \"+str(end_extract_pos)))\n",
    "resume_df2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "resume_df2[\"Sum_Experience_Val\"] = resume_df2[[\"Job_Title\",\"Company_Name\",\"Date_s\",\"City_Name\"]].sum(axis = 1)\n",
    "end_resume_df = False\n",
    "index = 0\n",
    "start = 0\n",
    "len_resume_df2,_ = resume_df2.shape\n",
    "start_end_df = pd.DataFrame()\n",
    "for index, row in enumerate(resume_df2):\n",
    "    if index+1 < len_resume_df2: \n",
    "        diff_val = resume_df2.Block_Pos[index+1] - resume_df2.Block_Pos[index]\n",
    "        if resume_df2.Sum_Val[index] == 0:\n",
    "            start_end_df = start_end_df.append({\"start\":resume_df2.Block_Pos[start],\"end\":resume_df2.Block_Pos[index],\n",
    "                                               \"sum_val\":resume_df2.Sum_Experience_Val[start:index+1].sum(axis=0)}, ignore_index = True)\n",
    "            start = index+1\n",
    "        else:\n",
    "            if  diff_val > 2:\n",
    "                start_end_df = start_end_df.append({\"start\":resume_df2.Block_Pos[start],\"end\":resume_df2.Block_Pos[index],\n",
    "                                                   \"sum_val\":resume_df2.Sum_Experience_Val[start:index+1].sum(axis=0)},ignore_index = True)\n",
    "                start = index+1\n",
    "            \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end</th>\n",
       "      <th>start</th>\n",
       "      <th>sum_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    end  start  sum_val\n",
       "0   9.0    9.0      0.0\n",
       "1  11.0   10.0      3.0\n",
       "2  18.0   17.0      3.0\n",
       "3  23.0   23.0      0.0"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_end_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n• Responsible for automation of services pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nBuilding and automation of storing data (gig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Experiences\n",
       "0  \\n• Responsible for automation of services pro...\n",
       "1  \\nBuilding and automation of storing data (gig..."
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#start_end_df = start_end_df[1:,:]\n",
    "finished = False\n",
    "index = 0 \n",
    "len_df,_ = start_end_df.shape\n",
    "experience_df = pd.DataFrame()\n",
    "counter = 1 \n",
    "for idx in range(0,len_df-1):\n",
    "    if start_end_df.sum_val[idx] > 0:\n",
    "        text_data = \"\"\n",
    "        for i in range(int(start_end_df.end[idx]+1),int(start_end_df.start[idx+1])):\n",
    "            text_data = text_data+\"\\n\"+resume_l[i]\n",
    "        counter += 1\n",
    "        experience_df = experience_df.append({\"Experiences\":text_data},ignore_index = True)\n",
    "        if (counter > 3):\n",
    "            break\n",
    "experience_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_df2 = resume_df2.assign(Sum_Val = 0)\n",
    "resume_df2[\"Sum_Val\"] = resume_df2[[\"Job_Title\",\"Company_Name\",\"Date_s\",\"City_Name\"]].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end</th>\n",
       "      <th>start</th>\n",
       "      <th>sum_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    end  start  sum_val\n",
       "0   9.0    9.0      0.0\n",
       "1  11.0   10.0      3.0\n",
       "2  18.0   17.0      3.0\n",
       "3  23.0   23.0      0.0"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_end_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Resume_Name', 'Block_Pos', 'Block_Title'], dtype='object')"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = resume_df[resume_df.Block_Title == \"Forms and Interfaces.\"].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Resume_Name</th>\n",
       "      <th>Block_Pos</th>\n",
       "      <th>Block_Title</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Date_s</th>\n",
       "      <th>City_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>0</td>\n",
       "      <td>Suma Dodmani</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>3</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>4</td>\n",
       "      <td>UNIVERSITY OF COLORADO</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>5</td>\n",
       "      <td>BOULDER</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>6</td>\n",
       "      <td>MS IN COMPUTER SCIENCE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>7</td>\n",
       "      <td>SPECIALIZATION: DATA SCIENCE AND</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>8</td>\n",
       "      <td>ENGINEERING</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>9</td>\n",
       "      <td>Graduated May 2019 Boulder, CO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>10</td>\n",
       "      <td>BVBCET</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>11</td>\n",
       "      <td>BE IN INFORMATION SCIENCE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>12</td>\n",
       "      <td>Graduated May 2015 Hubli, India</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>13</td>\n",
       "      <td>Cum. GPA: 8.96 / 10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>14</td>\n",
       "      <td>COURSEWORK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>15</td>\n",
       "      <td>GRADUATE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>16</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>17</td>\n",
       "      <td>Data Centered scale Computing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>18</td>\n",
       "      <td>Numerical Optimization</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>19</td>\n",
       "      <td>Natural Language Processing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>20</td>\n",
       "      <td>Design and Analysis of Algorithms</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>21</td>\n",
       "      <td>Principles of Numerical Computation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>22</td>\n",
       "      <td>Software Engineering</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>23</td>\n",
       "      <td>Convex Optimization</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>24</td>\n",
       "      <td>BigData Architecture</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>25</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>25</td>\n",
       "      <td>Database Systems</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>26</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>26</td>\n",
       "      <td>UNDERGRADUATE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>27</td>\n",
       "      <td>Distributed and Cloud Computing +</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>28</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>28</td>\n",
       "      <td>Practicum</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>29</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>29</td>\n",
       "      <td>Data Mining</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>30</td>\n",
       "      <td>Unix System Programming</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>31</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>31</td>\n",
       "      <td>Object Oriented Programming with C++</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>32</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>32</td>\n",
       "      <td>SKILLS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>33</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>33</td>\n",
       "      <td>PROGRAMMING</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>38</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>38</td>\n",
       "      <td>PHP • JavaScript • CSS • HTML</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>39</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>39</td>\n",
       "      <td>Familiar</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>40</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>40</td>\n",
       "      <td>C # • Assembly • R</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>41</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>41</td>\n",
       "      <td>TECHNOLOGIES</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>44</td>\n",
       "      <td>112712805.pdf</td>\n",
       "      <td>44</td>\n",
       "      <td>AWS• BigData• Spark • GIT•</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index    Resume_Name  Block_Pos                           Block_Title  \\\n",
       "0       0  112712805.pdf          0                          Suma Dodmani   \n",
       "1       3  112712805.pdf          3                             EDUCATION   \n",
       "2       4  112712805.pdf          4                UNIVERSITY OF COLORADO   \n",
       "3       5  112712805.pdf          5                               BOULDER   \n",
       "4       6  112712805.pdf          6                MS IN COMPUTER SCIENCE   \n",
       "5       7  112712805.pdf          7      SPECIALIZATION: DATA SCIENCE AND   \n",
       "6       8  112712805.pdf          8                           ENGINEERING   \n",
       "7       9  112712805.pdf          9        Graduated May 2019 Boulder, CO   \n",
       "8      10  112712805.pdf         10                                BVBCET   \n",
       "9      11  112712805.pdf         11             BE IN INFORMATION SCIENCE   \n",
       "10     12  112712805.pdf         12       Graduated May 2015 Hubli, India   \n",
       "11     13  112712805.pdf         13                   Cum. GPA: 8.96 / 10   \n",
       "12     14  112712805.pdf         14                            COURSEWORK   \n",
       "13     15  112712805.pdf         15                              GRADUATE   \n",
       "14     16  112712805.pdf         16                      Machine Learning   \n",
       "15     17  112712805.pdf         17         Data Centered scale Computing   \n",
       "16     18  112712805.pdf         18                Numerical Optimization   \n",
       "17     19  112712805.pdf         19           Natural Language Processing   \n",
       "18     20  112712805.pdf         20     Design and Analysis of Algorithms   \n",
       "19     21  112712805.pdf         21   Principles of Numerical Computation   \n",
       "20     22  112712805.pdf         22                  Software Engineering   \n",
       "21     23  112712805.pdf         23                   Convex Optimization   \n",
       "22     24  112712805.pdf         24                  BigData Architecture   \n",
       "23     25  112712805.pdf         25                      Database Systems   \n",
       "24     26  112712805.pdf         26                         UNDERGRADUATE   \n",
       "25     27  112712805.pdf         27     Distributed and Cloud Computing +   \n",
       "26     28  112712805.pdf         28                             Practicum   \n",
       "27     29  112712805.pdf         29                           Data Mining   \n",
       "28     30  112712805.pdf         30               Unix System Programming   \n",
       "29     31  112712805.pdf         31  Object Oriented Programming with C++   \n",
       "30     32  112712805.pdf         32                                SKILLS   \n",
       "31     33  112712805.pdf         33                           PROGRAMMING   \n",
       "32     38  112712805.pdf         38         PHP • JavaScript • CSS • HTML   \n",
       "33     39  112712805.pdf         39                              Familiar   \n",
       "34     40  112712805.pdf         40                    C # • Assembly • R   \n",
       "35     41  112712805.pdf         41                          TECHNOLOGIES   \n",
       "36     44  112712805.pdf         44            AWS• BigData• Spark • GIT•   \n",
       "\n",
       "    Job_Title  Company_Name  Date_s  City_Name  \n",
       "0           0             0       0          0  \n",
       "1           0             0       0          0  \n",
       "2           0             1       0          0  \n",
       "3           0             0       0          0  \n",
       "4           0             0       0          0  \n",
       "5           0             0       0          0  \n",
       "6           0             0       0          0  \n",
       "7           0             0       0          0  \n",
       "8           0             1       0          0  \n",
       "9           0             0       0          0  \n",
       "10          0             0       0          0  \n",
       "11          0             1       0          0  \n",
       "12          0             0       0          0  \n",
       "13          0             0       0          0  \n",
       "14          0             0       0          0  \n",
       "15          0             0       0          0  \n",
       "16          0             0       0          0  \n",
       "17          0             0       0          0  \n",
       "18          0             0       0          0  \n",
       "19          0             0       0          0  \n",
       "20          1             0       0          0  \n",
       "21          0             1       0          0  \n",
       "22          0             0       0          0  \n",
       "23          0             0       0          0  \n",
       "24          0             0       0          0  \n",
       "25          0             0       0          0  \n",
       "26          0             0       0          0  \n",
       "27          0             1       0          0  \n",
       "28          0             0       0          0  \n",
       "29          0             0       0          0  \n",
       "30          0             0       0          0  \n",
       "31          0             0       0          0  \n",
       "32          0             1       0          0  \n",
       "33          0             0       0          0  \n",
       "34          0             0       0          0  \n",
       "35          0             0       0          0  \n",
       "36          0             1       0          0  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_df2.loc[[47]]\n",
    "resume_df2.query('index < 46')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 8)"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_df = resume_df.reset_index()\n",
    "resume_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (HSS_Resumes)",
   "language": "python",
   "name": "pycharm-727f0d03"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
